<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Gaoustcer blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Gaoustcer blog">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Gaoustcer blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Haihan Gao">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Gaoustcer blog" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Gaoustcer blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-Dirichletprocess1" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/02/17/Dirichletprocess1/" class="article-date">
  <time class="dt-published" datetime="2023-02-17T11:33:08.000Z" itemprop="datePublished">2023-02-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/02/17/Dirichletprocess1/">Dirichletprocess1</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="dirichlet-process">Dirichlet Process</h1>
<h2 id="motivation">Motivation</h2>
<p>给定若干采样自GMM二维数据，希望聚类为若干类(求解GMM中的k) <span class="math display">\[
\log P(x) = \log \sum_{i=1}^k \alpha_i N(x|\mu_i,\sum_i)
\]</span></p>
<blockquote>
<p>每个instance属于一类最好，但是这个结果没有意义</p>
</blockquote>
<p>每个数据<span class="math inline">\(x_i\)</span>来自分布<span class="math inline">\(p(\theta_i),\theta_i\)</span>为分布的参数，并且 <span class="math display">\[
\theta_i |H(\theta)
\]</span></p>
<blockquote>
<p>参数的分布来自另一个分布，若<span class="math inline">\(H\)</span>是连续分布，则 <span class="math display">\[
H(\theta_1=\theta_2) = 0
\]</span> 因此得到N个分布，这也是不符合预期的，假设 <span class="math display">\[
\theta_i|G
\]</span> G是一个离散分布，并且 <span class="math display">\[
G|DP(\alpha,H),\alpha &gt;0
\]</span> 满足初始分布为H，参数为<span class="math inline">\(\alpha\)</span>的Dirichlet Process</p>
<ol type="1">
<li><span class="math inline">\(\alpha\)</span>控制分布的离散程度，<span class="math inline">\(\alpha\)</span>越大则G不那么离散，极端期望下<span class="math inline">\(\alpha = 0\)</span> G变成单点分布</li>
<li>H被称为Base measure</li>
</ol>
</blockquote>
<h2 id="construction-of-dirichlet-process">Construction of Dirichlet Process</h2>
<p>存在分布<span class="math inline">\(x|p(x)\to H(\theta)\)</span></p>
<h3 id="stick-breaking">Stick Breaking</h3>
<p>通过Stick Break采样一系列分布<span class="math inline">\(G_1,G_2,\cdots\)</span>，对应离散数据上的离散分布，随机分布(测度)可以看成在多个点(atom)上的权重</p>
<p>采样自H得到<span class="math inline">\(\theta_1\)</span>(atom)，对应的权重<span class="math inline">\(\pi_1\)</span>由如下方式生成</p>
<ol type="1">
<li>采样自<span class="math inline">\(\Beta\)</span>分布得到<span class="math inline">\(\beta_1|\Beta(1,\alpha)\)</span></li>
<li><span class="math inline">\(\pi_1 =\beta_1\)</span></li>
</ol>
<blockquote>
<p><span class="math display">\[
E[\beta ]= \frac{1}{1+\alpha}
\]</span></p>
</blockquote>
<p>采样第二个atom <span class="math inline">\(\theta_2|H\)</span>，确定它的权重<span class="math inline">\(\pi_2\)</span></p>
<ol type="1">
<li><span class="math inline">\(\beta_2|\Beta(1,\alpha)\)</span></li>
<li><span class="math inline">\(\pi_2 = (1-\pi_1)\beta_2\)</span></li>
</ol>
<p>得到一系列样本和权重 <span class="math display">\[
\theta_1,\theta_2,\theta_3,\cdots\\
\pi_1,\pi_2,\pi_3,\cdots
\]</span> 对应分布G取值和概率，显然G是离散分布(无论H是否为离散分布)</p>
<ol type="1">
<li><span class="math inline">\(\alpha = 0,\beta=1\)</span>，第一次采样将所有权重给第一个样本，随后样本权重为0，生成单点分布</li>
<li><span class="math inline">\(\alpha = \infty,\beta\to 0\)</span>，每次采样生成的<span class="math inline">\(\beta \to 0,\pi\to 0\)</span>，权重都很小，分布退化为均匀分布</li>
</ol>
<h2 id="dirichlet-dsitribution">Dirichlet Dsitribution</h2>
<h3 id="beta分布">Beta分布</h3>
<p>Beya分布来自于顺序统计量，考虑从[0,1]均匀分布中采样N个数，第k大的数应该满足分布 <span class="math display">\[
f(x) =\frac{n!}{(k-1)!(n-k)!} x^{k-1} (1-x)^{n-k}=\frac{\Gamma(n+1)}{\Gamma(k)\Gamma(n-k+1)} x^{k-1} (1-x)^{n-k}
\]</span></p>
<blockquote>
<p>可以看成某种程度上的二项分布，落在左侧有k-1个数，右侧是n-k个数</p>
</blockquote>
<p><code>Gamma</code>函数将阶乘推广到实数域，令<span class="math inline">\(\alpha = k,\beta = n-k+1\)</span>，得到 <span class="math display">\[
f(x) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1} (1-x)^{\beta -1} = \frac{1}{\Beta(\alpha ,\beta)}x^{\alpha-1}(1-x)^{\beta -1} \\
\Gamma(Z) =\int_0^{\infty} t^{z-1} e^{-t} d t,\Gamma(n+1) = n!\\
\Beta(x,y) =\int_0^1 t^{x-1}(1-t)^{y-1} dt =\frac{\Gamma(x)\Gamma(y)}{\Gamma(x+y)}
\]</span></p>
<h3 id="从贝叶斯推断角度理解beta分布">从贝叶斯推断角度理解Beta分布</h3>
<p>Beta分布包含两个参数<span class="math inline">\(\Beta(\alpha,\beta)\)</span>，密度函数写成 <span class="math display">\[
f(x) =\frac{1}{\Beta(\alpha,\beta)}x^{\alpha-1}(1-x)^{\beta -1}
\]</span></p>
<ol type="1">
<li><span class="math inline">\(\alpha = \beta =1\)</span>，退化为均匀分布</li>
<li><span class="math inline">\(\alpha = \beta = k\neq 1\)</span>，为中心在<span class="math inline">\(\frac{1}{2}\)</span>的均匀分布</li>
</ol>
<p>抛硬币为例，假设抛了三次硬币都是正面，能否判断硬币的两面都是正面？贝叶斯分布用于刻画先验分布，即没有任何实验的前提下，事件：硬币两面都是正面的概率满足的分布</p>
<p>两点理由使用beta分布做先验分布</p>
<ol type="1">
<li><span class="math inline">\(\Beta\)</span>分布调整参数可以有效刻画多种不同分布</li>
<li><span class="math inline">\(\Beta\)</span>分布在二项实验结果产生后仍然为<span class="math inline">\(\Beta\)</span>分布</li>
</ol>
<p>假设初始假设硬币是均匀的，即<span class="math inline">\(\Beta(1,1)\)</span>，二项分布下<span class="math inline">\(X|p\)</span>满足二项分布(p是一次实验成功的概率) <span class="math display">\[
X|p \ bin(n,p)
\]</span> 后验分布<span class="math inline">\(f(p|X=k)\)</span>写成 <span class="math display">\[
f(p|X=k) =\frac{P(X=k|p)f(p)}{P(X=k)}
\]</span> 记作<span class="math inline">\(f(p|X=k)\)</span>正比于<span class="math inline">\(P(X=k|p)f(p)\)</span>，带入得到 <span class="math display">\[
\begin{aligned}
f(p|X=k) &amp;= P(X=k|p)\frac{1}{\Beta(\alpha,\beta)}p^{\alpha-1}(1-p)^{\beta-1}\\
&amp;=C_{n}^k p^{k+\alpha-1} (1-p)^{n-k+\beta-1} \frac{1}{\Beta(\alpha,\beta)}\
\end{aligned}
\]</span> 显然变成了<span class="math inline">\(\beta(k+\alpha,n-k+\beta)\)</span>分布</p>
<h3 id="beta-binomial共轭">Beta-Binomial共轭</h3>
<p>在n个数第k个数顺序统计量的前提下，增加一个限制。从<code>Uni(0,1)</code>中再采样m个数 <span class="math display">\[
Y_1,Y_2,\cdots,Y_m |Uni(0,1)
\]</span> 知道<span class="math inline">\(Y_i\)</span>中有<span class="math inline">\(m_1\)</span>个数比顺序统计量k<span class="math inline">\(x_{(k)}\)</span>大，<span class="math inline">\(m_2\)</span>个小，求 <span class="math display">\[
P(x_{(k)}|Y_1,Y_2,\cdots,Y_m)
\]</span> 分布</p>
<p>知道<span class="math inline">\(x_{(k)}\)</span>先验分布是<span class="math inline">\(\Beta\)</span>分布 <span class="math display">\[
f(x_{(k)}=x)|\Beta (k,n-k+1,x)
\]</span> <span class="math inline">\(Y_i\)</span>相当于做了m次伯努利实验，符合二项分布<span class="math inline">\(m_1|B(m,p)\)</span> <span class="math display">\[
P(m_1|x_{(k)}=x) =B(m,p)
\]</span> 后验分布写成 <span class="math display">\[
P(x_{(k)}= x|m_1) = \frac{P(m_1|x_{(k)}=x)P(x_{(k)}=x ) }{P(m_1)}
\]</span></p>
<blockquote>
<ol type="1">
<li>知识：随机采样m个数，包含<span class="math inline">\(m_1\)</span>个数比X小，其余数比X大</li>
<li>先验：X采样自[0,1]上的分布<span class="math inline">\(f(x)\)</span></li>
</ol>
<p>知识表示为 <span class="math display">\[
P(m=m_1|x) = \frac{m!}{m_1!m_2!} x^{m_1}(1-x)^{m_2}  \\
\begin{aligned}
P(m=m_1)&amp; = \int_0^1 P(m=m_1|x) f(x) dx \\
&amp;=\int_0^1 \frac{m+1}{\Beta(m_1+1,m_2+1)} x^{m_1+k-1} (1-x)^{m_2+n-k} \frac{1}{\Beta(k,n-k+1)}\\
&amp;=(m+1) \frac{1}{\Beta(m_1+1,m_2+1)\Beta(k,n-k+1)}\Beta(m_1+k,m_2+n-k+1)
\end{aligned}
\]</span> 后验分布计算为 <span class="math display">\[
\begin{aligned}
f(x|m_1) &amp;= \frac{p(m_1|x)p(x)}{p(m_1)}\\
\end{aligned}
f(x|m_1)|\Beta(x|k+m_1,n-k+1+m_2)
\]</span></p>
</blockquote>
<h3 id="dirichlet-multinomial共轭">Dirichlet-Multinomial共轭</h3>
<p>考虑排序后的顺序统计量 <span class="math display">\[
X_1,X_2,\cdots,X_n
\]</span> 求 <span class="math display">\[
X_{k_1},X_{k_1+k_2}
\]</span> 的联合分布</p>
<p>从另一个角度考虑这个问题，<span class="math inline">\(X_{k_1},X_{k_1+k_2}\)</span>将区间分成三个部分</p>
<ol type="1">
<li><span class="math inline">\([0,x_1)\)</span>包含<span class="math inline">\(k_1-1\)</span>个元素</li>
<li><span class="math inline">\((x_1,x_1+x_2)\)</span>包含<span class="math inline">\(k_2-1\)</span>个元素</li>
<li><span class="math inline">\((x_1+x_2,1]\)</span>包含<span class="math inline">\(N - k_1 -k_2\)</span>个元素</li>
</ol>
<blockquote>
<p>这显然是一个多项式分布：假设做一次随机试验A存在三种结果，概率分别为 <span class="math display">\[
P(A_1) = p_1\\
P(A_2) = p_2\\
P(A_3) = p_3,p_1+p_2+p_3=1
\]</span> 做N次A实验，求 <span class="math display">\[
P(A_1 = k_1,A_2=k_2,A_3 = k_3),k_1+k_2+k_3 = N
\]</span> 概率 <span class="math display">\[
P(A_1= k_1,A_2 = k_2,A_3 = k_3) =C_{N}^{k_1,k_2,k_3} p_1^{k_1} p_2^{k_2}p_3^{k_3}
\]</span> 可以理解为 <span class="math display">\[
\begin{aligned}
P(A_1=k_1,A_2=k_2,A_3=k_3) &amp;= P(A_1=k_1,A_2=k_2|A_3=k_3)P(A_3=k_3)\\
&amp;=C_{N-k_3}^{k_1}  (\frac{p_1}{p_1+p_2})^{k_1}(\frac{p_2}{p_1+p_2})^{k_2} C_{N}^{k_3} p_3^{k_3} (p_1+p_2)^{k_1+k_2}\\
=\frac{N!}{k_3!k_1!k_2!} p_1^{k_1} p_2^{k_2} p_3^{k_3}
\end{aligned}
\]</span> 记作<span class="math inline">\(Multi(N,p_1,p_2,p_3)\)</span>，意味着做N次实验，每个事件发生的概率分别为<span class="math inline">\(p_1,p_2,p_3\)</span></p>
</blockquote>
<p>求解(先选择2个元素放在<span class="math inline">\(x_1,x_2\)</span>，随后变成<span class="math inline">\(Multi(N-2,x_1,x_2,x_3=(1-x_1-x_2))\)</span>) <span class="math display">\[
\begin{aligned}
f(x_1,x_2,x_3) &amp;= A_n^2 Multi(n-2,x_1,x_2,x_3)\\
&amp;= n(n-1)\frac{(n-2)!}{(k_1-1)!(k_2-1)!(n-k_1-k_2)!} x_1^{k_1-1}x_2^{k_2-1}x_3^{n-k_1-k_2}\\
&amp;= \frac{\Gamma(n+1)}{\Gamma(k_1)\Gamma(k_2)\Gamma(n-k_1-k_2+1)}
\end{aligned}
\]</span> 记作Dirichlet分布，同理可以讨论<span class="math inline">\(x_{k_1},x_{k_1+k_2},x_{k_1+k_2+k_3},\cdots\)</span>的联合分布，Dirichlet分布<span class="math inline">\(Dir(k_1,K_2,k_3)\)</span>写成 <span class="math display">\[
f(x_1,x_2,x_3) = \frac{\Gamma (\alpha_1+\alpha_2+\alpha_3)}{\Gamma (\alpha_1)\Gamma(\alpha_2)\Gamma(\alpha_3)}x_1^{\alpha_1-1}x_2^{\alpha_2-1}x_3^{\alpha_3-1}\\
\alpha_1 = k_1,\alpha_2=k_2,\alpha_3 = n-k_1-k_2+1,x_1+x_2+x_3=1
\]</span></p>
<h3 id="数学期望和方差">数学期望和方差</h3>
<blockquote>
<p>数学期望可以从如下角度考虑，对于<span class="math inline">\(x_1\)</span>的期望，实际上是顺序统计量<span class="math inline">\(x_{k_1}\)</span>的期望，计算 <span class="math display">\[
f(x_{k_1} = x) = C_{n}^{k_1}  x^{k_1}(1-x)^{n-k_1}\\
\begin{aligned}
E[x_1] &amp;= \frac{n!}{(n-k_1)!k_1!}\int_0^1 x^{k_1+1}(1-x)^{n-k_1} dx\\
&amp;=\frac{\Gamma(n+1)}{\Gamma(n-k_1+1)\Gamma(k_1+1)}\Beta(k_1+2,n-k_1+1)\\
&amp;=\frac{\Gamma(n+1)\Gamma(k_1+2)}{\Gamma(k_1+1)\Gamma(n+3)}\\
&amp;=\frac{k_1+1}{(n+2)(n+1)},n=\alpha_1+\alpha_2+\alpha_3-1
\end{aligned}
\]</span></p>
</blockquote>
<h2 id="characteristic-of-dirichlet-process">Characteristic of Dirichlet Process</h2>
<p>牢记：随机过程采样得到随机分布</p>
<p>Dirichlet Process任何时刻得到的分布G是离散分布，在离散点<span class="math inline">\(a_1,a_2,\cdots,a_d\)</span>上联合分布满足 <span class="math display">\[
(G(a_1),G(a_2),\cdots,G(a_d))|Dir(\alpha H(a_1),\alpha H(a_2),\cdots,\alpha H(a_d))
\]</span></p>
<blockquote>
<p><span class="math display">\[
x_1,x_2,\cdots,x_n|Dir(\alpha_1,\alpha_2,\cdots,\alpha_d)\\
E[x_i] = \frac{\alpha_i}{\sum_j \alpha_j}\\
Var[x_i]=\frac{\alpha_i(\sum_k \alpha_k - \alpha_i)}{(\sum_k \alpha_i)^2(\sum_k \alpha _k +1)}
\]</span></p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/02/17/Dirichletprocess1/" data-id="cle8ge6qe0000jk8w2wus012i" data-title="Dirichletprocess1" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Random-Process-Dirichlet-Process/" rel="tag">Random Process, Dirichlet Process</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-ContrastiveLearningOverview3" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/02/17/ContrastiveLearningOverview3/" class="article-date">
  <time class="dt-published" datetime="2023-02-17T11:28:13.000Z" itemprop="datePublished">2023-02-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/02/17/ContrastiveLearningOverview3/">ContrastiveLearningOverview3</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Contrastive-Learning-Introduction-III，不用负样本的对比学习"><a href="#Contrastive-Learning-Introduction-III，不用负样本的对比学习" class="headerlink" title="Contrastive Learning Introduction(III，不用负样本的对比学习)"></a>Contrastive Learning Introduction(III，不用负样本的对比学习)</h1><h2 id="BYOL-Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning"><a href="#BYOL-Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning" class="headerlink" title="BYOL(Bootstrap Your Own Latent A New Approach to Self-Supervised Learning)"></a>BYOL(Bootstrap Your Own Latent A New Approach to Self-Supervised Learning)</h2><p>通过自举(仅仅在正样本之间对比学习)学习好的特征表示，同时避免模型退化</p>
<p><img src="https://s2.loli.net/2023/02/16/mJBUMe4r8oCGj9A.png" alt="image-20230216175143509"></p>
<p>同样的instance通过两个数据增强得到$v$和$v^\prime$，通过两个编码器$f<em>\theta,f</em>\xi$和两个projection head $g<em>\theta,g</em>\xi$得到representation。使用动量更新$f<em>\xi,g</em>\xi$</p>
<h3 id="Predictor"><a href="#Predictor" class="headerlink" title="Predictor"></a>Predictor</h3><p>增加一个Prediction Network $q<em>\theta$(MLP)，使得预测结果和$z</em>\xi^\prime$尽量接近，输出的$y_\theta$用于下游任务</p>
<h3 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h3><script type="math/tex; mode=display">
\parallel q_\theta(z_\theta) - z^\prime_\xi\parallel_2^2</script><h3 id="问什么不会出现模型坍塌"><a href="#问什么不会出现模型坍塌" class="headerlink" title="问什么不会出现模型坍塌"></a>问什么不会出现模型坍塌</h3><p>projector/prediction包含两个Batch Normal</p>
<script type="math/tex; mode=display">
Linear \to BN \to ReLU\to BN\tag{MLP}\label{MLP}</script><p>Batch Normal会泄露样本中其它数据的特征(和平均数据的差别)，本质上是隐式的对比试验</p>
<h2 id="SimSiam-Exploring-Simple-Siamese-Representation-Learning"><a href="#SimSiam-Exploring-Simple-Siamese-Representation-Learning" class="headerlink" title="SimSiam(Exploring Simple Siamese Representation Learning)"></a>SimSiam(Exploring Simple Siamese Representation Learning)</h2><ol>
<li>无需正样本</li>
<li>无需batch size</li>
<li>无需动量编码器</li>
</ol>
<p><img src="https://s2.loli.net/2023/02/16/lJQzLWFV9gHeid6.png" alt="image-20230216180732377"></p>
<p>共享参数的两个编码器(没有动量更新，完全copy参数)，predictor同时作用于$x_1,x_2$，随后互相预测，计算<code>mse loss</code></p>
<script type="math/tex; mode=display">
x_1 \to p_1\to h_1,x_2\to p_2\to h_2\\
\mathcal{L} = D(p_1,h_2)+D(p_2,h_1)</script><h3 id="几个工作的对比"><a href="#几个工作的对比" class="headerlink" title="几个工作的对比"></a>几个工作的对比</h3><p><img src="https://s2.loli.net/2023/02/16/jK8zE5PvwMO4XHt.png" alt="image-20230216181120466"></p>
<ol>
<li><code>SimCLR</code>和<code>SwAV</code>计算正负样本embedding，优化<code>infonce loss</code>，区别是前者需要迭代两个编码器，后者只需要更新一个</li>
<li><code>BYOL</code>和<code>SimSiam</code>无需计算<code>infonce loss</code>，转化为预测问题，前者采用动量更新保持参数一致性，后者直接采用同一个网络+stop gradient</li>
</ol>
<h2 id="结合Transformer和对比学习"><a href="#结合Transformer和对比学习" class="headerlink" title="结合Transformer和对比学习"></a>结合Transformer和对比学习</h2><h3 id="Moco-v3"><a href="#Moco-v3" class="headerlink" title="Moco-v3"></a>Moco-v3</h3><p>解决自监督Transformer训练不稳定的问题，Backbone换成visual transformer，这种情况下大batch_size performance反而不好</p>
<blockquote>
<p>随机初始化patch transformer(tokenization，图片序列化)</p>
</blockquote>
<p>结合<code>infonce loss</code>和<code>predictive loss</code></p>
<h3 id="Dino-Self-distillation-with-no-labels"><a href="#Dino-Self-distillation-with-no-labels" class="headerlink" title="Dino(Self-distillation with no labels)"></a>Dino(Self-distillation with no labels)</h3><p><img src="https://s2.loli.net/2023/02/16/KUqm7XgtpcTxOu8.png" alt="image-20230216200246056"></p>
<p>添加centering避免模型坍塌</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/02/17/ContrastiveLearningOverview3/" data-id="cle8gag9x0002f88w5uvq7tf1" data-title="ContrastiveLearningOverview3" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Contrastive-Learning-Deep-Learning-Unsupervised-Learning/" rel="tag">Contrastive Learning, Deep Learning, Unsupervised Learning</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-ContrastiveLearningOverview1" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/02/17/ContrastiveLearningOverview1/" class="article-date">
  <time class="dt-published" datetime="2023-02-17T11:28:09.000Z" itemprop="datePublished">2023-02-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/02/17/ContrastiveLearningOverview1/">ContrastiveLearningOverview1</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Paper-Reading-Momentum-Contrast-for-Unsupervised-Visual-Representation-Learning"><a href="#Paper-Reading-Momentum-Contrast-for-Unsupervised-Visual-Representation-Learning" class="headerlink" title="Paper Reading(Momentum Contrast for Unsupervised Visual Representation Learning)"></a>Paper Reading(Momentum Contrast for Unsupervised Visual Representation Learning)</h1><p>无监督学习预训练的结果逼近有监督学习，对比学习用来挖掘instance之间的相似程度</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>相当于给样本打上伪标签(相似/不相似)</p>
<h3 id="Instance-Discrimination"><a href="#Instance-Discrimination" class="headerlink" title="Instance Discrimination"></a>Instance Discrimination</h3><p>给定一个数据集</p>
<script type="math/tex; mode=display">
x_1,x_2,\cdots,x_n</script><p>对每个instance用k种transformer生成k个增广instance</p>
<script type="math/tex; mode=display">
x_1^k ,x_1^2,\cdots,x_1^k</script><p>在$n\times (k+1)$大小的数据集中，instance和它的增广互为正样本(相似)，其余样本互为负样本</p>
<blockquote>
<p>每张图片自成一类</p>
</blockquote>
<p>学习特征，带入NCE loss</p>
<h3 id="动量"><a href="#动量" class="headerlink" title="动量"></a>动量</h3><p>加权平均</p>
<script type="math/tex; mode=display">
y_t = my_{t-1}+(1-m)x_t</script><p>当前输入依赖于上一时刻状态</p>
<h2 id="Abstract-amp-amp-Introduction"><a href="#Abstract-amp-amp-Introduction" class="headerlink" title="Abstract &amp;&amp; Introduction"></a>Abstract &amp;&amp; Introduction</h2><script type="math/tex; mode=display">
对比学习\to 字典查询\\
memory\ bank\to 队列</script><p>moving average encoder用于提取特征，采用动量更新的方法尽量和上一时刻状态保持一致</p>
<blockquote>
<p>Moco学习的特征可以简单地迁移到下游任务</p>
</blockquote>
<h3 id="Linear-Protocol"><a href="#Linear-Protocol" class="headerlink" title="Linear Protocol"></a>Linear Protocol</h3><p>测试特征提取网络的好坏，仅仅训练全连接网络作为分类器并在梯度更新时freeze特征提取网络</p>
<h3 id="gap-between-supervised-and-unsupervised-Learning"><a href="#gap-between-supervised-and-unsupervised-Learning" class="headerlink" title="gap between supervised and unsupervised Learning"></a>gap between supervised and unsupervised Learning</h3><p>对比学习=构建动态字典</p>
<p>对于$x_1$增广得到正样本对$x_1^1,x_1^2$，相对于数据集中其它样本$x_2,x_3,\cdots,x_n$是负样本</p>
<script type="math/tex; mode=display">
x_1^1\to^{E_1}\to f_1^1\\
x_1^2 \to ^{E_2}\to f_1^2\\
x_2,x_3,\cdots,x_n\to ^{E_2}\to f_n</script><p>两个特征提取器获取特征(也可以借助单一net)，字典查询指的是从一些key中找到和query相似的key，这里</p>
<ol>
<li>query：$f_1^1$正样本编码出的特征</li>
<li>keys：$f_1^2,f_2,f_3,\cdots,f_n$，负样本编码出的特征，希望查找到$f_1^2$</li>
</ol>
<p>重新记作</p>
<script type="math/tex; mode=display">
x_q\to^{E_1}\to q\\
x_k\to^{E_2}\to k_0,k_1,\cdots</script><p>希望</p>
<ol>
<li>字典尽量大</li>
<li>编码器一致性，指的是多个key应该借助相似的编码器生成</li>
</ol>
<h3 id="为什么用队列代替字典？"><a href="#为什么用队列代替字典？" class="headerlink" title="为什么用队列代替字典？"></a>为什么用队列代替字典？</h3><p>队列可以很大，但是每次更新只更新一个mini-batch大小的特征</p>
<blockquote>
<p>这样会破坏队列中元素的一致性，具体而言队列头和队列尾部特征来自不同的编码器，头的特征来自<strong>旧编码器</strong>，尾部特征来自<strong>新编码器</strong></p>
</blockquote>
<p>momentum encoder解决不一致问题，它的更新满足</p>
<script type="math/tex; mode=display">
\theta_k = m \theta_{k-1}+(1-m)\theta_q</script><p>落后于正样本encoder参数</p>
<blockquote>
<p>能否将Mask Auto Encoding作为代理任务？</p>
</blockquote>
<h2 id="论文精读"><a href="#论文精读" class="headerlink" title="论文精读"></a>论文精读</h2><ol>
<li>intro部分归纳无监督预训练在CV上表现不佳的原因在于离散/连续信号空间带来的差别，NLP上可以建立关于token的字典</li>
<li>Dynamic Dictionary: key采样自data，通过encoder编码为embedding，问题转化为字典中query查找的过程</li>
</ol>
<p><img src="https://s2.loli.net/2023/02/01/JMhfc15pO48Lb2i.png" alt="image-20230201114411771"></p>
<ol>
<li>字典被视为一个队列，当前mini-batch encode结果入队，旧encoder生成的结果出队。动量更新保证队列中元素的一致性</li>
<li>can be transferred to downstream tasks by fine-tuning</li>
</ol>
<h3 id="Method-Contrast-Learning-as-Dictionary-Look-up"><a href="#Method-Contrast-Learning-as-Dictionary-Look-up" class="headerlink" title="Method: Contrast Learning as Dictionary Look-up"></a>Method: Contrast Learning as Dictionary Look-up</h3><p>给定query q和一系列keys ${ k<em>0,k_1,\cdots,}$，其中包含唯一key $k</em>+$是查询的目标，Contrast Loss用于评估q和$k_+$相对于其它正负样本的相似程度，查询记作</p>
<script type="math/tex; mode=display">
q=f_q(x^q)</script><ol>
<li>$f_q$ encoder network</li>
<li>$x^q$ query sample</li>
</ol>
<h3 id="Contrast-Loss梯度回传的方式-Momentum-Contrast"><a href="#Contrast-Loss梯度回传的方式-Momentum-Contrast" class="headerlink" title="Contrast Loss梯度回传的方式 Momentum Contrast"></a>Contrast Loss梯度回传的方式 Momentum Contrast</h3><p><img src="https://s2.loli.net/2023/02/01/hwu1PjkBW5EgATo.png" alt="image-20230201152208102"></p>
<ol>
<li>end-to-end 通过contrastive loss同时更新key encoder和query encoder的参数，两个encoder不共享任何参数</li>
<li>memory-bank 使用一个encoder，维护memory bank，存储所有正负样本的embedding tensor(从梯度图上detach)。contrastive loss回传每更新一次encoder就重新计算一次memory bank。每次从memory bank中采样若干negative samples</li>
<li><code>Moco</code>有些类似强化学习中延迟更新的思想，key encoder采用动量更新</li>
</ol>
<h4 id="Use-queue-instead-of-memory-bank"><a href="#Use-queue-instead-of-memory-bank" class="headerlink" title="Use queue instead of memory bank"></a>Use queue instead of memory bank</h4><p>队列保证我们可以使用之前encoder的结果，希望key encoder改变不要太大因此使用动量更新的策略</p>
<blockquote>
<p>相比memory bank，避免了每次更新encoder都需要重新遍历data sample带来的开销</p>
</blockquote>
<h3 id="Pretext-Task构建正负样本对"><a href="#Pretext-Task构建正负样本对" class="headerlink" title="Pretext Task构建正负样本对"></a>Pretext Task构建正负样本对</h3><p>构建正样本对：同一张图片采取两种方式进行数据增强</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/02/17/ContrastiveLearningOverview1/" data-id="cle8gag9j0000f88w05aehydg" data-title="ContrastiveLearningOverview1" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Contrastive-Learning-Deep-Learning-Unsupervised-Learning/" rel="tag">Contrastive Learning, Deep Learning, Unsupervised Learning</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-ContrastiveLearningOverview2" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/02/14/ContrastiveLearningOverview2/" class="article-date">
  <time class="dt-published" datetime="2023-02-14T04:15:07.000Z" itemprop="datePublished">2023-02-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/02/14/ContrastiveLearningOverview2/">ContrastiveLearningOverview2</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1>对比无监督学习综述(II)</h1>
<h2 id="Moco">Moco</h2>
<h3 id="Contribution">Contribution</h3>
<ol>
<li>对比学习$\to $字典查询</li>
<li>队列+动量编码器解决
<ol>
<li>字典信息不一致</li>
<li>每次更新参数需要重新计算所有key embedding导致较大计算开销(而不是动量更新特征)</li>
</ol>
</li>
</ol>
<h3 id="实现">实现</h3>
<ol>
<li>数据增强，随机采样图片的子模块</li>
<li>$\tau = 0.07$</li>
</ol>
<h3 id="Moco-v2">Moco-v2</h3>
<p>在Moco基础上结合SimCLR提升Moco</p>
<ol>
<li>加了MLP</li>
<li>数据增强</li>
<li>更多epoch</li>
</ol>
<h2 id="SimCLR-Simple-Contrastive-Learning">SimCLR(Simple Contrastive Learning)</h2>
<h3 id="Methods">Methods</h3>
<p>对Mini-batch中的所有图片$x$，数据增强得到<br>
$$<br>
\hat x_i,\hat x_j<br>
$$<br>
互为正样本，和batch中之外的图片增强的样本互为负样本，通过共享权重的编码器得到表示<br>
$$<br>
h_i = f(\hat x_i),h_j = f(\hat x_j)<br>
$$<br>
引入一个mlp层 $g(\cdot)$<br>
$$<br>
z_i = g(h_i),z_j = g(h_j)<br>
$$<br>
在$z_i,z_j$之间做对比学习，采用normalized temperature-scaled交叉熵函数</p>
<ol>
<li>归一化特征</li>
<li>temperature作为loss函数的权重</li>
</ol>
<p>mlp层$g(\cdot)$仅仅用于训练，下游任务中只用h特征(预训练)。本文另一个特点是无需计算所有正负样本，所有正负样本对来自同一个mini-batch</p>
<h3 id="前向工作：InvaSpread">前向工作：InvaSpread</h3>
<p>mini-batch中相似的图片应该得到相似的特征表示(数据增强得到正样本)</p>
<blockquote>
<p>和SimCLR相比batch_size选择的太小，导致负样本不是特别多(更多的数据增强，更大的batch_size)</p>
</blockquote>
<h3 id="Experiment">Experiment</h3>
<ol>
<li>随机的裁剪和颜色变换是最有用的image trans</li>
<li>非线性编码器$g(\cdot)$比仅仅加一层MLP存在性能提升，但是特征维度并没有太大的影响</li>
</ol>
<h3 id="SimCLRv2（半监督学习）">SimCLRv2（半监督学习）</h3>
<ol>
<li>大量无监督数据对比学习方法预训练</li>
<li>少量有标签数据微调</li>
<li>生成teacher模型，为无监督数据打标签</li>
</ol>
<p>相比SimCLR</p>
<ol>
<li>更大的模型(backbone)</li>
<li>更深的非线性函数$g(\cdot)$</li>
<li>动量编码器</li>
</ol>
<h2 id="SwAV-Unsupervised-Learning-of-Visual-Features-by-Contrasting-Clustering-Assignment">SwAV(Unsupervised Learning of Visual Features by Contrasting Clustering Assignment)</h2>
<h3 id="motivation">motivation</h3>
<p>同一场景下对应不同view，给定一个view下的特征，能否推断另一view下的特征。</p>
<h3 id="compared-with-Contrastive-Learning">compared with Contrastive Learning</h3>
<p><img src="https://s2.loli.net/2023/02/14/H4xqmeBMDCNdSWQ.png" alt="image-20230214115041760"></p>
<p>instance classification这个任务要求自己和自己比，这个工作要求每个样本和<strong>聚类中心</strong>对比，$c\in \R^{D\times K}$</p>
<ol>
<li>K c dimension of center embedding</li>
<li>D number of centers</li>
</ol>
<p>生成同一样本两种数据增强的提取的特征<br>
$$<br>
x\to z_1,z_2<br>
$$<br>
基于center生成两个目标哦<br>
$$<br>
c\times z_1\to Q_1,c\times z_2\to Q_2<br>
$$<br>
如果$z_1,z_2$相似，可以借助$z_1$和c预测$Q_2$</p>
<p>$Q$在某种程度上是latent embedding z的预测结果的ground truth，通过swap prediction进行训练</p>
<h3 id="Advantage">Advantage</h3>
<ol>
<li>减少负样本的依赖</li>
<li>聚类中心具有特定语义含义(代表某一类数据)，传统Contrastive Learning中不能区分不同负样本和正样本的相似程度(类别不均衡)</li>
</ol>
<h3 id="Multi-Crop">Multi-Crop</h3>
<p>生成来自一个图片的两个正样本，往往正样本之间有重叠，希望同时使用多个正样本同时不增加计算成本</p>
<ol>
<li>选择两个较大的crop学习全局特征</li>
<li>选择若干较小crop学习局部特征</li>
</ol>
<blockquote>
<p>Multi-view</p>
</blockquote>
<h3 id="Refer">Refer</h3>
<p>Deep clustering</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/02/14/ContrastiveLearningOverview2/" data-id="cle4egxbs0003to8w88qj2ht6" data-title="ContrastiveLearningOverview2" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Contrastive-Learning-Deep-Learning-Unsupervised-Learning/" rel="tag">Contrastive Learning, Deep Learning, Unsupervised Learning</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-firstpost" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/02/13/firstpost/" class="article-date">
  <time class="dt-published" datetime="2023-02-13T12:43:15.000Z" itemprop="datePublished">2023-02-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/02/13/firstpost/">How to post a new article and establish local site with hexo</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1>Use of Hexo</h1>
<p>Thanks to Chatgpt which points out the right way to use Hexo to establish a local site and pub it to github service. Here are the record to publish a new article into github</p>
<h2 id="make-a-new-article">make a new article</h2>
<ol>
<li>enter hexo site dir</li>
<li>create a new article <code>hexo new articletitle</code> articletitle is the title of your article. Then you will find a new markdown file named <code>articletitle.md</code> in the <code>source/_post</code> dir</li>
<li>edit the markdown file and add tags to it</li>
</ol>
<h2 id="post-local-dir-to-github-page-service">post local dir to github page service</h2>
<p>When you encounter a newly created hexo repo(without relationship with any github pages)</p>
<ol>
<li>create repo in remote github service</li>
<li>config the _config.yml file deploy sector.
<ol>
<li>type:git</li>
<li>repo:Your <a target="_blank" rel="noopener" href="http://github.io">github.io</a> repo</li>
<li>branch:master</li>
</ol>
</li>
<li>install git deploy extension with <code>npm install hexo-deployer-git --save</code>(This may fail because of file lock,for example you have opened the github repo locally in a text editor)</li>
<li>generate static pages with <code>hexo generate</code></li>
<li>deploy into pages <code>hexo deploy</code></li>
<li>you will see your pages later</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/02/13/firstpost/" data-id="cle4egxbl0000to8w05dga1t9" data-title="How to post a new article and establish local site with hexo" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Use-of-Hexo/" rel="tag">Use of Hexo</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-hello-world" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/02/13/hello-world/" class="article-date">
  <time class="dt-published" datetime="2023-02-13T12:24:14.062Z" itemprop="datePublished">2023-02-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/02/13/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start">Quick Start</h2>
<h3 id="Create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/02/13/hello-world/" data-id="cle4egxbp0001to8wfr4c672t" data-title="Hello World" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Contrastive-Learning-Deep-Learning-Unsupervised-Learning/" rel="tag">Contrastive Learning, Deep Learning, Unsupervised Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Random-Process-Dirichlet-Process/" rel="tag">Random Process, Dirichlet Process</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Use-of-Hexo/" rel="tag">Use of Hexo</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Contrastive-Learning-Deep-Learning-Unsupervised-Learning/" style="font-size: 20px;">Contrastive Learning, Deep Learning, Unsupervised Learning</a> <a href="/tags/Random-Process-Dirichlet-Process/" style="font-size: 10px;">Random Process, Dirichlet Process</a> <a href="/tags/Use-of-Hexo/" style="font-size: 10px;">Use of Hexo</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/">February 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/02/17/Dirichletprocess1/">Dirichletprocess1</a>
          </li>
        
          <li>
            <a href="/2023/02/17/ContrastiveLearningOverview3/">ContrastiveLearningOverview3</a>
          </li>
        
          <li>
            <a href="/2023/02/17/ContrastiveLearningOverview1/">ContrastiveLearningOverview1</a>
          </li>
        
          <li>
            <a href="/2023/02/14/ContrastiveLearningOverview2/">ContrastiveLearningOverview2</a>
          </li>
        
          <li>
            <a href="/2023/02/13/firstpost/">How to post a new article and establish local site with hexo</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 Haihan Gao<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>